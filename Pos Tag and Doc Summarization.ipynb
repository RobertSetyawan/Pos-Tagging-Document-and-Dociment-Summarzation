{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f3190b47",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pos Tagging a simple sentences\n",
    "import nltk\n",
    "import re\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "from nltk import word_tokenize\n",
    "from nltk import pos_tag\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.cluster.util import cosine_distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "137fdd8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sample sentence\n",
    "star_wars = \"\"\"It is a period of civil war. Rebel spaceships, striking from a hidden base, have won their firts victory againts\n",
    "the evil Galactic Empire. During the battle, Rebel spies managed to steal secret plans to the\n",
    "Empire's ultimate weapon, the DEATH STAR, an armored space station with enough power to destroy an entire\n",
    "planet. Pursued by the Empire's sinister agents, Princess Leia races home aboard her starship, custodian of \n",
    "the stolen plans that can save her people and restore freedom to the galaxy...\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "14b3c370",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('It', 'PRP'), ('is', 'VBZ'), ('a', 'DT'), ('period', 'NN'), ('of', 'IN'), ('civil', 'JJ'), ('war', 'NN'), ('Rebel', 'NNP'), ('spaceships', 'VBZ'), ('striking', 'VBG'), ('from', 'IN'), ('a', 'DT'), ('hidden', 'JJ'), ('base', 'NN'), ('have', 'VBP'), ('won', 'VBN'), ('their', 'PRP$'), ('firts', 'NNS'), ('victory', 'NN'), ('againts', 'VBZ'), ('the', 'DT'), ('evil', 'JJ'), ('Galactic', 'NNP'), ('Empire', 'NNP'), ('During', 'IN'), ('the', 'DT'), ('battle', 'NN'), ('Rebel', 'NNP'), ('spies', 'NNS'), ('managed', 'VBD'), ('to', 'TO'), ('steal', 'VB'), ('secret', 'JJ'), ('plans', 'NNS'), ('to', 'TO'), ('the', 'DT'), ('Empire', 'NNP'), ('s', 'NN'), ('ultimate', 'JJ'), ('weapon', 'IN'), ('the', 'DT'), ('DEATH', 'NNP'), ('STAR', 'NNP'), ('an', 'DT'), ('armored', 'JJ'), ('space', 'NN'), ('station', 'NN'), ('with', 'IN'), ('enough', 'JJ'), ('power', 'NN'), ('to', 'TO'), ('destroy', 'VB'), ('an', 'DT'), ('entire', 'JJ'), ('planet', 'NN'), ('Pursued', 'VBN'), ('by', 'IN'), ('the', 'DT'), ('Empire', 'NNP'), ('s', 'NN'), ('sinister', 'NN'), ('agents', 'NNS'), ('Princess', 'NNP'), ('Leia', 'NNP'), ('races', 'VBZ'), ('home', 'NN'), ('aboard', 'IN'), ('her', 'PRP$'), ('starship', 'JJ'), ('custodian', 'NN'), ('of', 'IN'), ('the', 'DT'), ('stolen', 'VBN'), ('plans', 'NNS'), ('that', 'WDT'), ('can', 'MD'), ('save', 'VB'), ('her', 'PRP$'), ('people', 'NNS'), ('and', 'CC'), ('restore', 'NN'), ('freedom', 'NN'), ('to', 'TO'), ('the', 'DT'), ('galaxy', 'NN')]\n"
     ]
    }
   ],
   "source": [
    "clean_words = re.sub(\"[^a-zA-Z]\",\" \",star_wars)\n",
    "clean_words = \" \".join(clean_words.split()) #remove multiple whitespace\n",
    "tokens = word_tokenize(clean_words)\n",
    "pos_tokens = pos_tag(tokens)\n",
    "print(pos_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d702a506",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_article(filename):\n",
    "    file = open(filename, \"r\")\n",
    "    filedata = file.readlines()\n",
    "    article = filedata[0].split(\". \")\n",
    "    sentences = []\n",
    "    \n",
    "    for sentence in article:\n",
    "        print(sentence)\n",
    "        sentences.append(sentence.replace(\"[^a-zA-Z]\", \" \").split(\" \"))\n",
    "    sentences.pop()\n",
    "    return sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "251c8ab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentence_sim(sentence1, sentence2, stopwords = None):\n",
    "    if stopwords is None:\n",
    "        stopwords = []\n",
    "    sentence1 = [w.lower() for w in sentence1]\n",
    "    sentence2 = [w.lower() for w in sentence2]\n",
    "    \n",
    "    all_words = list(sentence1+sentence2)\n",
    "    \n",
    "    vector1 = [0] * len(all_words)\n",
    "    vector2 = [0] * len(all_words)\n",
    "    \n",
    "    #build the vector for 1st sentence\n",
    "    for w in sentence1:\n",
    "        if w in stopwords:\n",
    "            continue\n",
    "        vector1[all_words.index(w)] += 1\n",
    "    #build the vector for 2nd sentence\n",
    "    for w in sentence2:\n",
    "        if w in stopwords:\n",
    "            continue\n",
    "        vector2[all_words.index(w)] += 1\n",
    "    return 1-cosine_distance(vector1,vector2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "da4a4548",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_similarity_mat(sentences, stop_words):\n",
    "    #Create an empty similarity matrix\n",
    "    sim_matrix = np.zeros((len(sentences), len(sentences)))\n",
    "    for idx1 in range(len(sentences)):\n",
    "        for idx2 in range(len(sentences)):\n",
    "            if idx1 == idx2 : #ignore if both are same sentences\n",
    "                continue\n",
    "            sim_matrix[idx1][idx2] = sentence_sim(sentences[idx1], sentences[idx2],stop_words)\n",
    "    return sim_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e1f7cafe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_summary(filename, top_n=5):\n",
    "    stop_words = stopwords.words('english')\n",
    "    summarize_text = []\n",
    "    \n",
    "    #Step 1 : Read Text and tokenize\n",
    "    sentences = read_article(filename)\n",
    "    #print(\"The Sentences are : \\n\",sentences)\n",
    "    \n",
    "    #Step 2 : Generate similarity matrix across sentences\n",
    "    sentence_sim_matrix = build_similarity_mat(sentences,stop_words)\n",
    "    \n",
    "    #Step 3 : Rank sentences in similarity matrix\n",
    "    sentences_sim_graph = nx.from_numpy_array(sentence_sim_matrix)\n",
    "    scores = nx.pagerank(sentences_sim_graph)\n",
    "    \n",
    "    #Step 4 : Sort the rank and pick the top snetence\n",
    "    ranked_sentence = sorted(((scores[i],s) for i,s in enumerate(sentences)), reverse = True)\n",
    "    print(\"Indexes of top ranked sentence order are\" , ranked_sentence)\n",
    "    for i in range(top_n):\n",
    "        summarize_text.append(\" \".join(ranked_sentence[i][1]))\n",
    "    \n",
    "    #Step 5 : Print the output\n",
    "    print(\"Summarize text = \\n\", \". \".join(summarize_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ca7b054e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Different types of restorative imaging systems such as Computed Tomography (CT), Single- Photon Emission Computed Tomography (SPECT), and Magnetic Resonance Imaging (MRI) are utilized to give important data about nature, dimension, vicinity and metabolism of cere- brum tumor aiding determination\n",
      "These modalities are utilized in combination to give the most elevated data about the cerebrum tumor\n",
      "MRI is a non-intrusive system that uses radio recurrence signals to create the internal images under the influence of an extremely amazing attractive field\n",
      "Distinctive MRI modalities produce various kinds of tissue contrast images, subsequently giving important auxiliary data and empowering analysis and segmentation of tumor along with their subregions\n",
      "Cerebrum tumor segmentation from MRI is a criti- cal errand which includes different covering pathology, medical resonance materal science, radiologistâ€™s discernment, and image analysis dependent on intensity and shape\n",
      "There are numerous difficulties related to tumor fragmentation\n",
      "The tumor might be of any dimension, may have an assortment of shapes, and may emerge at any location\n",
      "The manual segmen- tation is a troublesome and tedious task, which makes an attractive computerized cerebrum tumor segmentation technique\n",
      "The challenges related with programmed cerebrum tumor segmentation have offered to various methodologies.\n",
      "\n",
      "Indexes of top ranked sentence order are [(0.17854050554966938, ['These', 'modalities', 'are', 'utilized', 'in', 'combination', 'to', 'give', 'the', 'most', 'elevated', 'data', 'about', 'the', 'cerebrum', 'tumor']), (0.1520505693426727, ['Distinctive', 'MRI', 'modalities', 'produce', 'various', 'kinds', 'of', 'tissue', 'contrast', 'images,', 'subsequently', 'giving', 'important', 'auxiliary', 'data', 'and', 'empowering', 'analysis', 'and', 'segmentation', 'of', 'tumor', 'along', 'with', 'their', 'subregions']), (0.14507465857143487, ['Cerebrum', 'tumor', 'segmentation', 'from', 'MRI', 'is', 'a', 'criti-', 'cal', 'errand', 'which', 'includes', 'different', 'covering', 'pathology,', 'medical', 'resonance', 'materal', 'science,', 'radiologistâ€™s', 'discernment,', 'and', 'image', 'analysis', 'dependent', 'on', 'intensity', 'and', 'shape']), (0.143429731861414, ['The', 'manual', 'segmen-', 'tation', 'is', 'a', 'troublesome', 'and', 'tedious', 'task,', 'which', 'makes', 'an', 'attractive', 'computerized', 'cerebrum', 'tumor', 'segmentation', 'technique']), (0.11937693316687867, ['There', 'are', 'numerous', 'difficulties', 'related', 'to', 'tumor', 'fragmentation']), (0.11569480173747552, ['Different', 'types', 'of', 'restorative', 'imaging', 'systems', 'such', 'as', 'Computed', 'Tomography', '(CT),', 'Single-', 'Photon', 'Emission', 'Computed', 'Tomography', '(SPECT),', 'and', 'Magnetic', 'Resonance', 'Imaging', '(MRI)', 'are', 'utilized', 'to', 'give', 'important', 'data', 'about', 'nature,', 'dimension,', 'vicinity', 'and', 'metabolism', 'of', 'cere-', 'brum', 'tumor', 'aiding', 'determination']), (0.09996369728816701, ['The', 'tumor', 'might', 'be', 'of', 'any', 'dimension,', 'may', 'have', 'an', 'assortment', 'of', 'shapes,', 'and', 'may', 'emerge', 'at', 'any', 'location']), (0.04586910248228799, ['MRI', 'is', 'a', 'non-intrusive', 'system', 'that', 'uses', 'radio', 'recurrence', 'signals', 'to', 'create', 'the', 'internal', 'images', 'under', 'the', 'influence', 'of', 'an', 'extremely', 'amazing', 'attractive', 'field'])]\n",
      "Summarize text = \n",
      " These modalities are utilized in combination to give the most elevated data about the cerebrum tumor. Distinctive MRI modalities produce various kinds of tissue contrast images, subsequently giving important auxiliary data and empowering analysis and segmentation of tumor along with their subregions. Cerebrum tumor segmentation from MRI is a criti- cal errand which includes different covering pathology, medical resonance materal science, radiologistâ€™s discernment, and image analysis dependent on intensity and shape. The manual segmen- tation is a troublesome and tedious task, which makes an attractive computerized cerebrum tumor segmentation technique. There are numerous difficulties related to tumor fragmentation\n"
     ]
    }
   ],
   "source": [
    "#lets begin with some example\n",
    "generate_summary(\"example4.txt\",5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea11a713",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
